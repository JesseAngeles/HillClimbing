\chapter{Operador de Selección}

La función de selección elige las parejas (o subconjuntos) de individuos que fungirán como padres para reproducirse, combinar sus genes y generar a la siguiente nueva generación. 

A continuación se presentan algunas funciones de selección, las cuales (en su mayoria) requieren de los siguientes parámetros:
\begin{itemize}
	\item population: Subconjunto de la población a la cual se le aplica el algoritmo.
	\item objective: Función de evaluación.
\end{itemize}

Algunas de las funciones son las siguientes:

\section{Universal Random}

La selección aleatoria universal (\textit{Universal Sampling}) es una variante estocástica de la selección proporcional que busca reducir la varianza introducida por la aleatoriedad. En lugar de seleccionar los individuos uno por uno, se generan múltiples puntos equidistantes sobre el intervalo $[0,1]$ para garantizar una muestra más representativa de la población, según sus probabilidades acumuladas.

Sea $n$ el número de individuos a seleccionar, se generan $n$ números equidistantes:
\[
r_i = \frac{i + u}{n} \quad \text{para } i = 0, 1, ..., n-1
\]
donde $u \sim U(0,1)$ es un número aleatorio uniformemente distribuido.

Cada número $r_i$ se mapea sobre la distribución acumulada de probabilidades para determinar a qué individuo seleccionar.

\begin{algorithm}[H]
	\caption{Universal Random Selection \\ \textbf{Input:} \{population, objective\}}
	\begin{algorithmic}[1]
		\State scores $\gets$ [objective($i$) for $i$ in population]
		\If{any score $<$ 0}
		\State scores $\gets$ scores - min(scores) \Comment{Normalización para evitar valores negativos}
		\EndIf
		\State total $\gets$ sum(scores)
		\State probabilities $\gets$ [score / total for score in scores]
		\State cumulative $\gets$ acumulada(probabilities)
		\State $u \gets$ random.uniform(0, 1)
		\For{$i = 0$ \textbf{to} population\_size}
		\State $r \gets \frac{i + u}{population\_size}$
		\State parents[$i$] $\gets$ individuo correspondiente a $r$ en la distribución acumulada
		\EndFor \\
		\Return parents
	\end{algorithmic}
	\label{alg:universal_random}
\end{algorithm}

Este método asegura una cobertura más uniforme de la población en comparación con la selección proporcional simple, reduciendo la varianza en la selección. Es particularmente útil cuando se desea mantener una representación proporcional sin depender completamente de la aleatoriedad individual de cada extracción.


\section{Tournament}

El algoritmo \ref{alg:tournament_selection} recibe de manera adicional el parámetro \textit{selection\_rate}, que define el porcentaje de la población que participará en cada torneo.

Dada una población $P$, se selecciona aleatoriamente un subconjunto $Q \subseteq P$. El individuo $q_i$ con la mayor aptitud $f(q_i)$ es seleccionado para formar parte del conjunto de padres $S$:
\[
S = \left\{ \arg\max_{q \in Q} f(q) \,\middle|\, Q \subseteq P \right\}
\]

\begin{algorithm}[H]
	\caption{Tournament Selection \\ \textbf{Input:} \{population, objective, selection\_rate\}}
	\begin{algorithmic}[1]
		\For{$i = 0$ \textbf{to} population\_size}
		\State $k \gets$ population\_size $\times$ selection\_rate
		\State candidates $\gets$ random.sample(population, $k$)
		\State scores $\gets$ []
		\For{cada $j$ en candidates}
		\State scores.append(objective($j$))
		\EndFor
		\State max\_score $\gets$ max(scores)
		\State index $\gets$ scores.index(max\_score)
		\State parents[$i$] $\gets$ candidates[index]
		\EndFor \\
		\Return parents
	\end{algorithmic}
	\label{alg:tournament_selection}
\end{algorithm}

Este método es eficiente para poblaciones de cualquier tamaño. Además, el parámetro \textit{selection\_rate} permite controlar la presión selectiva: torneos pequeños fomentan la diversidad, mientras que torneos grandes intensifican la explotación de los individuos más aptos.

\section{Proportional}

La selección proporcional (también conocida como \textit{roulette wheel selection}) asigna a cada individuo una probabilidad de ser seleccionado proporcional a su aptitud. Es un método estocástico que favorece a los individuos más aptos, pero permite la selección de individuos menos aptos con menor probabilidad, promoviendo así la diversidad.

Sea $P$ la población con $n$ individuos y $f(p_i)$ la función de aptitud del individuo $p_i$. La probabilidad de seleccionar al individuo $p_i$ se define como:

\[
\Pr(p_i) = \frac{f(p_i)}{\sum_{j=1}^{n} f(p_j)}
\]

\begin{algorithm}[H]
	\caption{Proportional Selection \\ \textbf{Input:} \{population, objective\}}
	\begin{algorithmic}[1]
		\State scores $\gets$ [objective($i$) for $i$ in population]
		\If{any score $<$ 0}
		\State scores $\gets$ scores - min(scores) \Comment{Normalización para evitar negativos}
		\EndIf
		\State total $\gets$ sum(scores)
		\State probabilities $\gets$ [score / total for score in scores]
		\State cumulative $\gets$ acumulada(probabilities)
		\For{$i = 0$ \textbf{to} population\_size}
		\State $r \gets$ random.uniform(0, 1)
		\State parents[$i$] $\gets$ individuo correspondiente a $r$ en la distribución acumulada
		\EndFor \\
		\Return parents
	\end{algorithmic}
	\label{alg:proportional_selection}
\end{algorithm}

Este método es intuitivo y funciona bien cuando las diferencias de aptitud entre individuos no son extremas. Sin embargo, si las diferencias son muy marcadas, puede provocar convergencia prematura. También es sensible a funciones de aptitud negativas o cercanas a cero, por lo que puede requerir normalización.


\section{Negative Assortative Mating}

El apareamiento negativo asortativo busca maximizar la diversidad genética al emparejar individuos que sean lo más diferentes posible entre sí. Este método es útil para evitar la convergencia prematura, ya que fomenta la exploración del espacio de soluciones.

Se utiliza una función de similitud $d(a, b)$ que cuantifica cuán parecidos son dos individuos $a$ y $b$. Esta función puede estar basada en distancia euclidiana, Hamming, o alguna otra métrica según el tipo de representación del cromosoma. El objetivo es seleccionar, para cada individuo, una pareja que minimice dicha similitud.

\[
\text{Para cada } p_i \in P_{\text{seleccionado}},\quad p_j = \arg\min_{x \in P} \, d(p_i, x)
\]

\begin{algorithm}[H]
	\caption{Negative Assortative Mating \\ \textbf{Input:} \{population, similarity\_function\}}
	\begin{algorithmic}[1]
		\State num\_pairs $\gets$ population\_size / 2
		\State selected $\gets$ random.sample(population, num\_pairs)
		\State parents $\gets$ []
		\For{cada $p_i$ en selected}
		\State distances $\gets$ [similarity\_function($p_i$, $x$) for $x$ in population]
		\State remove $p_i$ de la población temporal para evitar emparejar consigo mismo
		\State partner $\gets$ individuo con menor valor de distancia
		\State parents.append(($p_i$, partner))
		\EndFor \\
		\Return parents
	\end{algorithmic}
	\label{alg:negative_assortative}
\end{algorithm}

Este método es particularmente útil en etapas tempranas del algoritmo evolutivo, donde la diversidad es crucial. Sin embargo, puede ser computacionalmente costoso, especialmente si se requiere calcular similitud entre todos los pares posibles en poblaciones grandes. Además, no garantiza que los individuos seleccionados sean de alta aptitud, por lo que suele combinarse con otros métodos de selección para mejorar su eficacia.