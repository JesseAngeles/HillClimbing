%Config
\documentclass[12pt,twoside]{article}
\usepackage[spanish,es-tabla]{babel}
\usepackage[a4paper]{geometry}

\usepackage{graphicx}               % Para incluir imágenes
\usepackage{amsmath}                % Para el manejo de matemáticas
\usepackage{url}
\usepackage{array}					% Para ajustar el texto en la celda
\usepackage{tabularx}
\usepackage{lipsum}
\usepackage{enumitem}

%opening
\title{Solución de problemas mediante ascensión de colinas}
\author{Erick Jesse Angeles López}


% Definir un comando para palabras clave
\newcommand{\keywords}[1]{%
	\begin{center}
		\textbf{Palabras clave:} #1
	\end{center}
}

\renewcommand{\baselinestretch}{1}
\setcounter{page}{1}
\setlength{\textheight}{21.6cm}
\setlength{\textwidth}{14cm}
\setlength{\oddsidemargin}{1cm}
\setlength{\evensidemargin}{1cm}
\pagestyle{myheadings}
\thispagestyle{empty}
\markboth{\small{Ángeles López Erick Jesse}}{\small{Solución de problemas mediante ascensión de colinas}}
\date{}

\begin{document}
	
	\begin{center}
		
		% Contenido izquierdo - Imagen
		\begin{minipage}{0.17\textwidth}
			\centering
			\includegraphics[width=0.7\textwidth]{img/cic_logo.png} % Ajusta esta línea
		\end{minipage}
		\begin{minipage}{.55\textwidth}
			\centering
			{\Large Instituto Politécnico Nacional}\\
			{\Large Escuela Superior de Cómputo}\\
			{\Large Centro de investigación en Computación}
		\end{minipage}
		\begin{minipage}{0.17\textwidth}
			\centering
			\includegraphics[width=0.9\textwidth]{img/escom_logo} % Ajusta esta línea
		\end{minipage}			
	\end{center}
	
	
	\centerline{\bf Ingeniería en Inteligencia Artificial, Metaheuristicas}
	
	\centerline{\bf Fecha: 06-03-24}
	
	\centerline{}
	
	%\centerline{}
	
	
	\begin{center}
		\Large{\textsc{Solución de problemas mediante ascensión de colinas}} 
	\end{center}
	\centerline{}
	\centerline{\bf {\textit{Presenta}}}
	\centerline{}
	\centerline{\bf {Angeles López Erick Jesse\footnote{eangelesl1700@alumno.ipn.mx}}}
	
	
	
	\newtheorem{Theorem}{\quad Theorem}[section]
	
	\newtheorem{Definition}[Theorem]{\quad Definition}
	
	\newtheorem{Corollary}[Theorem]{\quad Corollary}
	
	\newtheorem{Lemma}[Theorem]{\quad Lemma}
	
	\newtheorem{Example}[Theorem]{\quad Example}
	
	\bigskip
	
	\bigskip
	
	\begin{abstract} 
		A continuación se describe el comportamiento del algoritmo \textit{Hill Climbing} y sus variaciones para resolver diferentes tipos de problemas. Se analizan las ventajas, desventajas del algoritmo, como funciona internamente cada variación y cuales son las condiciones para resolver dos de los problemas mas conocidos en computación: \textit{knapsack problem} y \textit{travel salesman problem}.
	\end{abstract}
	
	\keywords{Algoritmo, Hill Climibing, Pseudocódigo, Resultado óptimo}
	
	\clearpage
	
	\tableofcontents
	\clearpage
		
	\section{Hill Climbing}
	
	Algoritmo iterativo que comienza con una solución aleatoria del problema, luego intenta encontrar un mejor resultado variando un elemento de la solución. Si la variación produce una mejora en el resultado, ahora este nuevo estado es la mejor solución. Este proceso se repite hasta que no exista un mejor camino que tomar.
	 
	Este algoritmo solo puede alcanzar un optimo local (máximo o mínimo según el problema) pues unicamente tiene conocimiento de la vecindad. Una alternativa para encontrar el optimo global es repetir la ascensión de colinas desde múltiples puntos, donde el mejor de los óptimos locales sera el optimo global.
	
	Este algoritmo se compone de:
	\begin{itemize}
		\item \textbf{Estado inicial}: Se inicia con una solución aleatoria
		\item \textbf{Estado de los vecinos}: Calcular los estados de los vecinos y si optimizan o empeoran la solución
		\item \textbf{Moverse al mejor vecino}: Si uno de los vecinos ofrece una mejor solución, se mueve a ese estado
		\item \textbf{Finalización}: Repetir el paso anterior hasta que ninguno de los vecinos ofrezca una mejor solución. En este punto ya se alcanzo el óptimo.
	\end{itemize}
	
	\subsubsection{Ventajas}
	
	\begin{itemize}
		\item \textbf{Optimo local}: Permite realizar búsqueda en amplitud y encontrar óptimos locales. Tiene variaciones para encontrar el optimo local mas rápido o incluso otra variación que aumenta las posibilidades de encontrar un óptimo global.
		
		\item \textbf{Sencillez}: Es un algoritmo fácil de implementar, ademas que no requiere estructuras de datos complejas ni almacenamiento constante, pues unicamente tiene conocimiento del estado del estado actual y de los vecinos, no de la trayectoria que ha realizado.
		
		\item \textbf{Búsqueda sin información completa}: Si no se conoce todo el espacio de búsqueda, puede ser una buena alternativa para definir y mapear el entorno. Esto puede reducir la complejidad al momento de querer explorar el espacio.
	\end{itemize}
	
	
	\subsubsection{Desventajas}
	
	\begin{itemize}
		\item \textbf{Óptimo global}: Partiendo de un único inicio, Hill Climbing no puede encontrar un óptimo local (La mayoría de las veces). Para solucionarlo utilizando el mismo algoritmo, sería necesario repetir el algoritmo pero con múltiples posiciones para encontrar todos los máximos locales y escoger el mejor.
		
		\item \textbf{Cordilleras y corredores}: Supongamos un terreno donde la respuesta optima esta en dos direcciones (2 ejes), como Hill Climbing actualiza un único elemento del vector a la vez, tendrá que moverse en zig-zag para alcanzar el objetivo.  Si los lados de la cordillera son muy pronunciados el algoritmo se ve forzado a realizar movimiento mas pequeños, lo que aumenta la cantidad de tiempo para escalar la cordillera.
		
		\item \textbf{Mesetas}: Si todas las opciones a las que puede moverse no mejoran ni empeoran entonces se esta en una meseta. El algoritmo no tiene una forma de determinar la próxima dirección que debe de tomar o si es la mejor solución. 
	\end{itemize}

	\subsection{Aplicaciones}

	\begin{itemize}
		\item Resolución de problemas combinatorios: Aquellos problemas cuya solución sea la combinación de diferentes parámetros y que se alcanzable de manera gradual puede ser resuelto mediante \textit{Hill Climging} y sus variables. Esto se debe a que en cada paso que se de, unicamente se modifica un parámetro.
		
		\item Único pico o valle: Si la función que se desea optimizar tiene un único valor optimo, entonces, por la naturaleza del algoritmo,  este encontrara el camino para llegar a dicho optimo, sin importar cual de todas las variaciones utilice.
		
		\item Ajustes finos: Si ya se tiene un resultado pero se desea afinar los parámetros, \textit{Hill Climbing} puede encontrar el camino que maximice dichos parámetros para obtener aun mejores resultados. Esto se debe a que la opción propuesta ya esta cerca del óptimo local pero no puede ser alcanzado por el tamaño de los pasos.
		
		\item Problemas de planificación: Si el espacio de soluciones es relativamente suave, pequeñas modificaciones pueden mejorar la eficiencia sin requerir de ajuste completo, por ejemplo  el acomodo de horarios para evitar solapamientos y horas muertas.
	\end{itemize}

	
	\subsection{Resultados de Forrest y Mitchel}

	Al evaluar diferentes estrategias de ascensión de colinas, los autores demuestran que no existe un algoritmo ``óptimo'' para todos los casos, sino que cada variación del algoritmo se enfoca en un aspecto diferentes. Mientras que SAHC y NAHC no lograron encontrar el optimo en el tiempo estipulado, RMHC lo logra en un tiempo significativamente mas rápido al realizar menos evaluación de la función de aptitud.
	
	Ciertamente existen  algunas limitaciones. Las funciones \textit{Royal Road} son intencionalmente simples que favorece ciertos comportamientos. Estas condiciones ideales pueden discernir los resultados de aplicaciones a problemas reales, con mas ruido, o con mayor complejidad. Ademas, estos algoritmos dependen unicamente de los valores de la función de aptitud, no considera otros aspectos que podrían ser esenciales para mejorar los resultados o la velocidad en que se obtienen.
	
	Estas condiciones ideales permiten al algoritmo de ascensión de colinas tener mejores resultados que los algoritmos genéticos, pero puede que esta ventaja sea exclusiva por la naturaleza del problema que se desea resolver, evaluar diferentes escenarios permitiría explorar diferentes comportamientos ante condiciones volátiles.


	\clearpage
	\section{Pseudocódigos}
	
	\subsection{Hill Climbing}
	
	Busca dentro de los vecinos el primer mejor estado que encuentre y se mueve a esa posición.
	
	\begin{enumerate}
		\item Interar $N$ veces:
		\begin{enumerate}
			\item Seleccionar un estado inicial de forma arbitraria \textit{current\_state}
			\item Iterar sobre los vecinos \textit{neighbor} del estado actual \textit{current\_state}:
			\begin{enumerate}
				\item Si la función objetivo del vecino es mejor que la función objetivo del estado actual, moverse a ese vecino y repetir el paso b). 
			\end{enumerate}
			\item Guardar \textit{current\_state} y repetir el paso a).
		\end{enumerate}
		\item El resultado óptimo es el mejor \textit{current\_state} conseguido.
	\end{enumerate}
	
	\subsection{Steepest-Ascent Hill Climbing (SAHC)}

	Busca dentro de todos los vecinos el mejor caso y se mueve a esa posición.	
	
	\begin{enumerate}
		\item Interar $N$ veces:
		\begin{enumerate}
			\item Seleccionar un estado inicial de forma arbitraria \textit{current\_state}
			\item Iterar sobre los vecinos del estado actual \textit{current\_state}:
			\begin{enumerate}
				\item Calcular la función objetivo del vecino y almacenarla
			\end{enumerate}
			\item Elige el vecino con la mejor función objetivo.
			\item Si la mejor función objetivo no es mejor que la función objetivo del estado actual, entonces guardar \textit{current\_state} y repetir el paso a).
			\item Si la mejor función objetivo es mejor que la función objetivo del estado actual, moverse a ese vecino y repetir el paso b).
		\end{enumerate}
		\item El resultado óptimo es el mejor \textit{current\_state} conseguido.
	\end{enumerate}
	
	\subsection{Next-Ascent Hill Climbing (NAHC)}
	
	Ordena todos los vecinos, y escoge el estado con la mínima mejora.
	
	\begin{enumerate}
		\item Interar $N$ veces:
		\begin{enumerate}
			\item Seleccionar un estado inicial de forma arbitraria \textit{current\_state}
			\item Iterar sobre los vecinos \textit{neighbor} del estado actual \textit{current\_state}:
			\begin{enumerate}
				\item Si la función objetivo del vecino es mejor que la función objetivo del estado actual, moverse a ese vecino. 
			\end{enumerate}
			\item Guardar \textit{current\_state} y repetir el paso a).
		\end{enumerate}
		\item El resultado óptimo es el mejor \textit{current\_state} conseguido.
	\end{enumerate}
	
	\subsection{Random-Mutation Hill Climbing (RMHC)}
	
	Escoge un estado de forma aleatoria, si es mejor entonces se mueve.
	
	\begin{enumerate}
		\item Interar $N$ veces:
		\begin{enumerate}
			\item Seleccionar un estado inicial de forma arbitraria \textit{current\_state}
			\item Seleccionar un vecino de forma arbitraria. 
			\item Si la función objetivo del vecino es mejor que la función objetivo del estado actual, moverse a ese vecino y repetir el paso b).
		\end{enumerate}
		\item El resultado óptimo es \textit{current\_state}.
	\end{enumerate}
	
	
	\clearpage
	\section{Problemas}
	
	\subsection{Knapsack problem}
	
	Dado un conjunto de $n$ ítems \[I = \{1,2, \dots, n \}\] Donde cada ítem $i$ tiene un valor $v_i \geq 0$ y un peso $w_i \geq 0$ y dada una mochila con capacidad máxima $W$, se busca seleccionar un subconjunto de ítems que maximice el valor total sin exceder la capacidad.
	
	Podemos representar los elementos dentro de la mochila como un vector binario: 
	\[ x = (x_1, x_2, \dots , x_n) \; \text{con } x_i \in \{0, 1\} \]
	Donde:
	\begin{itemize}
		\item $x_i = 0$ si el ítem no esta en la mochila
		\item $x_i = 1$ si el ítem si esta en la mochila
	\end{itemize}
	
	Para calcular el valor $v(x)$ y el peso $w(x)$ de la mochila sumamos los valores que si se encuentren dentro de ella:
	\begin{gather*}
		v(x) = \sum_{i = 1}^{n} v_i x_i \\
		w(x) = \sum_{i = 1}^{n} w_i x_i 
	\end{gather*}
	
	El objetivo, es encontrar el mayor $v(x)$ siempre que el peso $w(x)$ no exceda el peso máximo $W$. 
	
	\begin{itemize}
		\item El conjunto de estados posibles son todas las cadenas binarias de tamaño $n$: \[ S = \{ x \in \{ 0, 1  \}^n \} \]
		
		\item El estado inicial se genera de manera arbitraria. Se crea una cadena de tamaño $n$ con ceros y un numero uno asignado en una posición aleatoria.
		
		\item Se busca maximizar el valor de la mochila. La función objetivo suma los valores de los objetos dentro de la mochila. Si el peso de la mochila excede el limite, entonces se le asigna una ganancia nula.
		\[
		f(x) =
		\begin{cases} 
			v(x), & \text{si } w(x) \leq W \\ 
			0, & \text{si } w(x) > W
		\end{cases}
		\]
		
		\item Entonces, un estado $x_j$ es un estado final si genera mayor aptitud en comparación de los demás $x_i$ generados: \[f(x_j) \geq f(x_i) \; \forall x_i \in S\]
		
		\item La operación que genere los vecinos sera \textit{Bit flip} que intercambia un 0 por un 1 y viceversa en la posición $i$.
		
	\end{itemize}
	
	\subsection{Travel Salesman Problem (TSP)}
	
	Dado un numero de $n$ ciudades \[ C = \{1,2, \dots , n\} \] Y una matriz simétrica $M$ de las distancias entre las ciudades, se busca encontrar el camino hamiltoniano con menor distancia a recorrer.
	
	Podemos representar la trayectoria de las ciudades como un vector de enteros:
	\[ x = (x_1, x_2, \dots, x_n) \; \text{con } x_i \in [1, n] \]
	Donde:
	\begin{itemize}
		\item $x_i = c$ es la ciudad $c$ visitada en la i-ésima posición. Es necesario que cada $c$ sea único en cada ruta $x$.
	\end{itemize}
	
	Para calcular la distancia, iteramos el vector en orden y consultamos las distancias de cada par en la matriz $M$: 
	\[ d(x) = \sum_{i = 1}^{n - 1} M(x_i, x_{i + 1}) \]
	
	El objetivo, es encontrar la ruta $x$ que minimice la distancia $d(x)$ siempre que la ruta no tenga ciudades $c$ repetidas.
	
	\begin{itemize}
		\item El conjunto de estados posibles son todas las cadenas de enteros de tamaño $n$: \[ S = \{ x \in [1, n]^n \} \]
		
		\item El estado inicial se genera de manera arbitraria. Se selecciona un numero en el rango al azar y se coloca en la ultima posición de la ruta. Este paso se repite para todos los números restantes (No se puede repetir un numero). 
	
		\item Se busca minimizar la ruta. La función objetivo suma todas las distancias de la ruta planeada. Si una ciudad se visita mas de una vez, entonces se le asigna una ganancia nula.
		\[
		f(x) =
		\begin{cases} 
			d(x), & \text{si } \forall c \in C \colon \{ c \in x \} \\ 
			\infty, & \text{si } \exists c \in C \colon \{c \notin x\}
		\end{cases}
		\]
		Esto significa que:
		\begin{itemize}
			\item Se le asigna $d(x)$ si todas las ciudades se encuentran en la ruta. Dado que la ruta es del mismo tamaño que el numero de ciudades, si aparecen todas las ciudades, entonces no hay ciudades repetidas.
			\item Se le asigna 0 si existe una ciudad que no aparezca en la ruta. Si una ciudad no aparece en la ruta, significa que al menos una ciudad aparece dos veces, por lo que se repite.
		\end{itemize}
	
	\item Entonces, un estado $x_j$ es un estado final si genera una menor aptitud en la comparación de los demás $x_i$ generados: \[ f(x_j) \leq f(x_i) \; \forall x_i \in S \]
	
	\item La operación que genere los vecinos sera \textit{Swap}, ya que asegura unicamente cambiar el orden de los elementos sin tener que repetir ciudades.
	\end{itemize}
	
	Nótese que el estado inicial puede ser un estado de aceptación. Si realizamos puras operaciones \textit{Swap}, no estamos añadiendo ni quitando ciudades, sino que unicamente se cambia el orden. Por lo que podemos redefinir la función objetivo como: \[ f(x) = d(x) \] Y el conjunto de estados posibles como cualquier vector de tamaño $n$ que tenga números únicos en rango de $[1,n]$: \[ S = \{ x \in \{1, 2, \dots, n  \}^n | \forall x_i \colon \forall x_j \colon x_i \neq x_j \}\]
	
	\subsection{Minimizar de la función}
	
	Obtener los mínimos de la función \[ f(x) = \ \sum_{i = 1}^{D} x_i^2, \; \text{ con } -10 \geq x_i \geq 10 \].
	
	Dado un vector de $D$ números en el rango de $[-10, 10]$, se busca obtener el valor mínimo del sumatoria  de sus cuadrados.
	
	\begin{itemize}
		\item El conjunto de estados posibles son todas las cadenas de enteros en dicho intervalo: \[ S = \{ x \in [-10, 10]^n \} \]
		
		\item El estado inicial se genera de forma arbitraria como un vector de $D$ números en el rango establecido $[-10, 10]$
		
		\item Un estado de aceptación $x_j$ es aquel que produzca el menor valor de aptitud en la función comparando con los demás $x_i$ generados: \[ f(x_j) \leq f(x_i) \; \forall x_i \in S\] 
	\end{itemize}

\end{document}
